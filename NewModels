import json
import logging
import requests
from redis import Redis
import pandas as pd
from typing import Optional, Union

class DataFetcher:
    """Class to handle data fetching from Tableau Server."""
    def __init__(self, server_url: str, api_token: str):
        self.server_url = server_url
        self.api_token = api_token
        self.logger = logging.getLogger(__name__)

    def fetch_data(self) -> pd.DataFrame:
        """Fetch data from Tableau Server and return as a DataFrame."""
        try:
            headers = {'Authorization': f'Bearer {self.api_token}'}
            response = requests.get(f'{self.server_url}/api/data', headers=headers, timeout=600)
            response.raise_for_status()
            data = response.json()
            # Convert JSON data to DataFrame (adjust based on actual Tableau API response structure)
            df = pd.DataFrame(data)
            self.logger.info("Successfully fetched data from Tableau Server.")
            return df
        except Exception as e:
            self.logger.error(f"Failed to fetch data: {str(e)}")
            raise

class DataCache:
    """Class to manage caching with Redis."""
    def __init__(self, redis_client: Redis):
        self.redis = redis_client
        self.logger = logging.getLogger(__name__)

    def set_data(self, key: str, df: pd.DataFrame, ttl: int = 3600) -> None:
        """Cache DataFrame as JSON string with an optional time-to-live (TTL)."""
        try:
            # Convert DataFrame to JSON string for Redis storage
            value = df.to_json(orient='records')
            self.redis.setex(key, ttl, value)
            self.logger.info(f"Cached data with key: {key}")
        except Exception as e:
            self.logger.error(f"Failed to cache data: {str(e)}")
            raise

    def get_data(self, key: str) -> Optional[pd.DataFrame]:
        """Retrieve data from cache and return as DataFrame."""
        try:
            data = self.redis.get(key)
            if data:
                # Convert JSON string back to DataFrame
                return pd.read_json(data, orient='records')
            return None
        except Exception as e:
            self.logger.error(f"Failed to retrieve cached data: {str(e)}")
            return None

class MetricComputer:
    """Class to compute metrics from DataFrame data."""
    def __init__(self, df: pd.DataFrame):
        self.df = df
        self.logger = logging.getLogger(__name__)

    def compute(self, metric_name: str) -> Union[float, int, None]:
        """Compute a specific metric from the DataFrame."""
        try:
            if self.df.empty:
                raise ValueError("No data available for computation")
            
            if metric_name == "total_count":
                return len(self.df)
            elif metric_name == "avg_value":
                if "value" not in self.df.columns:
                    raise ValueError("'value' column not found in DataFrame")
                return self.df["value"].mean()
            else:
                self.logger.warning(f"Unknown metric: {metric_name}")
                return None
                
            self.logger.info(f"Computed metric: {metric_name}")
        except Exception as e:
            self.logger.error(f"Error computing metric {metric_name}: {str(e)}")
            return None

# Example usage
if __name__ == "__main__":
    # Configure logging
    logging.basicConfig(level=logging.INFO)
    
    # Initialize components
    fetcher = DataFetcher("https://tableau.example.com", "your-api-token")
    redis_client = Redis(host='localhost', port=6379, db=0)
    cache = DataCache(redis_client)
    
    # Fetch and cache data
    try:
        df = fetcher.fetch_data()
        cache.set_data("tableau_data", df)
        
        # Retrieve from cache and compute metrics
        cached_df = cache.get_data("tableau_data")
        if cached_df is not None:
            computer = MetricComputer(cached_df)
            total = computer.compute("total_count")
            avg = computer.compute("avg_value")
            print(f"Total Count: {total}, Average Value: {avg}")
    except Exception as e:
        logging.error(f"Main execution failed: {str(e)}")
